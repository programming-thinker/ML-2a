{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "625744e6",
   "metadata": {},
   "source": [
    "# <center>Assignment 2A – Machine Learning</center>\n",
    "\n",
    "### <center>Albin Lindqvist (13986236) - Lankun Chen (13591509) – Li Ren (13478516)</center>\n",
    "\n",
    "#### <center>Group 7</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fe0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ad963",
   "metadata": {},
   "source": [
    "# II-a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6687f78",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89945d",
   "metadata": {},
   "source": [
    "## 1.1 Classification on Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaba60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "white_data = pd.read_csv(\"winequality-white.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52eab5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LogisticRegression red wine dataset   0.6125\n",
      "Score for LogisticRegression white wine dataset 0.5404\n",
      "Set of possible labels for both datasets: {3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_r_train, X_r_test, y_r_train, y_r_test = train_test_split(\n",
    "    red_data.drop([\"quality\"], axis=1), red_data[\"quality\"], random_state=100\n",
    ")\n",
    "X_w_train, X_w_test, y_w_train, y_w_test = train_test_split(\n",
    "    white_data.drop([\"quality\"], axis=1), white_data[\"quality\"], random_state=100\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(random_state=100, max_iter=500)),\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_r_train, y_r_train)\n",
    "print(\n",
    "    \"Score for LogisticRegression red wine dataset  \",\n",
    "    round(pipe.score(X_r_test, y_r_test), 4),\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(random_state=100, max_iter=500)),\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_w_train, y_w_train)\n",
    "print(\n",
    "    \"Score for LogisticRegression white wine dataset\",\n",
    "    round(pipe.score(X_w_test, y_w_test), 4),\n",
    ")\n",
    "\n",
    "print(\"Set of possible labels for both datasets:\", (set(y_w_train) | set(y_r_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b92c14",
   "metadata": {},
   "source": [
    "##### Explain:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386c01c",
   "metadata": {},
   "source": [
    "The main advantage of multi-class is that it much clearer, since the quality is actually discrete, and so a quality of 6.482234 would never exists in the real world. \n",
    "\n",
    "The disadvantage is that it cannot extrapolate, i.e. the multi-class model can't predict outside of the existing label set: $\\{3,4,5,6,7,8,9\\}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0b7fc",
   "metadata": {},
   "source": [
    "# Part 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d62eb9",
   "metadata": {},
   "source": [
    "## 2.1  Analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a767c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(\"train.csv\",index_col = 0)\n",
    "test = pd.read_csv(\"test.csv\",index_col = 0)\n",
    "test_label = pd.read_csv(\"test_label.csv\",index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34508fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12870 entries, 13829 to 20137\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        12870 non-null  int64 \n",
      " 1   job        12870 non-null  object\n",
      " 2   marital    12870 non-null  object\n",
      " 3   education  12870 non-null  object\n",
      " 4   default    12870 non-null  object\n",
      " 5   balance    12870 non-null  int64 \n",
      " 6   housing    12870 non-null  object\n",
      " 7   loan       12870 non-null  object\n",
      " 8   contact    12870 non-null  object\n",
      " 9   day        12870 non-null  int64 \n",
      " 10  month      12870 non-null  object\n",
      " 11  campaign   12870 non-null  int64 \n",
      " 12  pdays      12870 non-null  int64 \n",
      " 13  previous   12870 non-null  int64 \n",
      " 14  poutcome   12870 non-null  object\n",
      " 15  y          12870 non-null  object\n",
      "dtypes: int64(6), object(10)\n",
      "memory usage: 1.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>21</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2488</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>30</td>\n",
       "      <td>jun</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15949</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1738</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>21</td>\n",
       "      <td>nov</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         job  marital  education default  balance housing loan  \\\n",
       "ID                                                                         \n",
       "11264   21     student   single  secondary      no     2488      no   no   \n",
       "15949   53  technician  married  secondary      no     1738      no  yes   \n",
       "\n",
       "        contact  day month  campaign  pdays  previous poutcome    y  \n",
       "ID                                                                   \n",
       "11264  cellular   30   jun         6    169         3  success  yes  \n",
       "15949  cellular   21   nov         2     -1         0  unknown   no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See non null count, and type of data\n",
    "train.info()\n",
    "\n",
    "# See two random entries\n",
    "train.sample(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97178102",
   "metadata": {},
   "source": [
    "## 2.2 Pepare Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43420a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of categorical columns\n",
    "catetgorical = [\n",
    "    \"job\",\n",
    "    \"marital\",\n",
    "    \"education\",\n",
    "    \"default\",\n",
    "    \"housing\",\n",
    "    \"loan\",\n",
    "    \"contact\",\n",
    "    \"month\",\n",
    "    \"poutcome\",\n",
    "]\n",
    "# List of numerical columns\n",
    "numerical = [\"age\", \"balance\", \"campaign\", \"pdays\", \"day\", \"previous\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdbc4d9",
   "metadata": {},
   "source": [
    "### Define a function that can encode category variables and make a Pipeline at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65155ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from typing import Union, List, Dict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_train = train.drop([\"y\"], axis=1)\n",
    "y_train = train[\"y\"]\n",
    "X_test = test\n",
    "y_test = test_label\n",
    "\n",
    "\n",
    "def get_scaler_and_ohe(\n",
    "    classifier: Union[LogisticRegression, LinearSVC, KNeighborsClassifier,DecisionTreeClassifier,RandomForestClassifier],\n",
    "    scaler: Union[Union[StandardScaler, MinMaxScaler], None] = None,\n",
    ") -> Pipeline:\n",
    "    \"\"\"Creates a pipeline, that one hot encoeds the categorical variables and scales the variables (if wanted). The names in the pipe are the same as the parameter names. I.e. scaler and classifier.\n",
    "\n",
    "    Args:\n",
    "        classifier (Union[LogisticRegression, LinearSVC, KNeighborsClassifier]): classifier\n",
    "        scaler (Union[Union[StandardScaler, MinMaxScaler], None], optional): scaler to use. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: Appropiate pipeline for the given parameters/models.\n",
    "    \"\"\"\n",
    "    if scaler:\n",
    "        ct = ColumnTransformer(\n",
    "            [\n",
    "                (\"scaling\", scaler, numerical),\n",
    "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), catetgorical),\n",
    "            ]\n",
    "        )\n",
    "        return Pipeline([(\"scaler\", ct), (\"classifier\", classifier)])\n",
    "    ct = ColumnTransformer(\n",
    "        [(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), catetgorical)]\n",
    "    )\n",
    "    return Pipeline([(\"scaler\", ct), (\"classifier\", classifier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a08f3",
   "metadata": {},
   "source": [
    "### Define some functions for subsequent modeling and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09240387",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings()\n",
    "def grid_search_and_test(model: Pipeline, params: Dict[str, List[float]]) -> None:\n",
    "    \"\"\"Prints the best parameters found for the model, and the score on the test data\"\"\"\n",
    "    gsc = GridSearchCV(model, param_grid=params, n_jobs=4, error_score=0.0)\n",
    "    gsc.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters found are:\", gsc.best_params_)\n",
    "    model.set_params(**gsc.best_params_)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    scores = {\n",
    "        \"Accuracy\": [accuracy_score(y_test, pred)],\n",
    "        \"Macro Averaged Precision\": [precision_score(y_test, pred, average=\"macro\")],\n",
    "        \"Macro Average Recall\": [recall_score(y_test, pred, average=\"macro\")],\n",
    "        \"F1 Macro\": [f1_score(y_test, pred, average=\"macro\")],\n",
    "        \"Micro Average Precision\": [precision_score(y_test, pred, average=\"micro\")],\n",
    "        \"Micro Average Recall\": [recall_score(y_test, pred, average=\"micro\")],\n",
    "        \"F1 Micro\": [f1_score(y_test, pred, average=\"micro\")],\n",
    "    }\n",
    "    score_df = pd.DataFrame(scores)\n",
    "\n",
    "    return score_df\n",
    "\n",
    "\n",
    "def test_scalers(\n",
    "    model: Union[LogisticRegression, LinearSVC, KNeighborsClassifier,DecisionTreeClassifier,RandomForestClassifier],\n",
    "    params: Dict[str, List[float]],\n",
    "    name: str = \"\",\n",
    ") -> None:\n",
    "    \"\"\"Test the model on Standard Scaler, Min Max Scaler and no scaler, and report the appropiate scores.\"\"\"\n",
    "    print(f\"No Scaler, {name}\")\n",
    "    pipe1 = get_scaler_and_ohe(model)\n",
    "    df_none = grid_search_and_test(pipe1, params=params)\n",
    "\n",
    "    print(\"~\" * 60)\n",
    "    print(f\"Standard Scaler, {name}\")\n",
    "    pipe2 = get_scaler_and_ohe(scaler=StandardScaler(), classifier=model)\n",
    "    df_std = grid_search_and_test(pipe2, params=params)\n",
    "\n",
    "    print(\"~\" * 60)\n",
    "    print(f\"MinMax Scaler, {name}\")\n",
    "    pipe3 = get_scaler_and_ohe(scaler=MinMaxScaler(), classifier=model)\n",
    "    df_min_max = grid_search_and_test(pipe3, params=params)\n",
    "\n",
    "    df_std[\"Scaler\"] = [\"Standard Scaler\"]\n",
    "    df_min_max[\"Scaler\"] = [\"Min Max Scaler\"]\n",
    "    df_none[\"Scaler\"] = [\"No Scaler\"]\n",
    "\n",
    "    df_comb = pd.concat([df_none, df_std, df_min_max])\n",
    "    df_comb = df_comb.set_index(\"Scaler\")\n",
    "\n",
    "    return df_comb.transpose()\n",
    "\n",
    "\n",
    "def df_diff_maker(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Function that gets the difference between no scaler and the two different type of scalers used. The difference is also scaled up to make it easier to comprehend.\"\"\"\n",
    "    data[\"diff_std\"] = (data[\"Standard Scaler\"] - data[\"No Scaler\"]) * 1000\n",
    "    data[\"diff_min_max\"] = (data[\"Min Max Scaler\"] - data[\"No Scaler\"]) * 1000\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb277c",
   "metadata": {},
   "source": [
    "## 2.3 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f688133",
   "metadata": {},
   "source": [
    "### (a) For a LinearSVC classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d39bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Scaler, LinearSVC\n",
      "Best parameters found are: {'classifier__C': 0.14563484775012445}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Standard Scaler, LinearSVC\n",
      "Best parameters found are: {'classifier__C': 3.2374575428176398}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MinMax Scaler, LinearSVC\n",
      "Best parameters found are: {'classifier__C': 0.7906043210907702}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Scaler</th>\n",
       "      <th>No Scaler</th>\n",
       "      <th>Standard Scaler</th>\n",
       "      <th>Min Max Scaler</th>\n",
       "      <th>diff_std</th>\n",
       "      <th>diff_min_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.773712</td>\n",
       "      <td>0.775810</td>\n",
       "      <td>0.776276</td>\n",
       "      <td>2.097413</td>\n",
       "      <td>2.563505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro Averaged Precision</th>\n",
       "      <td>0.773394</td>\n",
       "      <td>0.775228</td>\n",
       "      <td>0.776474</td>\n",
       "      <td>1.834119</td>\n",
       "      <td>3.079773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <td>0.663385</td>\n",
       "      <td>0.667209</td>\n",
       "      <td>0.667546</td>\n",
       "      <td>3.823549</td>\n",
       "      <td>4.160363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Macro</th>\n",
       "      <td>0.679555</td>\n",
       "      <td>0.683990</td>\n",
       "      <td>0.684424</td>\n",
       "      <td>4.435840</td>\n",
       "      <td>4.869213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average Precision</th>\n",
       "      <td>0.773712</td>\n",
       "      <td>0.775810</td>\n",
       "      <td>0.776276</td>\n",
       "      <td>2.097413</td>\n",
       "      <td>2.563505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average Recall</th>\n",
       "      <td>0.773712</td>\n",
       "      <td>0.775810</td>\n",
       "      <td>0.776276</td>\n",
       "      <td>2.097413</td>\n",
       "      <td>2.563505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Micro</th>\n",
       "      <td>0.773712</td>\n",
       "      <td>0.775810</td>\n",
       "      <td>0.776276</td>\n",
       "      <td>2.097413</td>\n",
       "      <td>2.563505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Scaler                    No Scaler  Standard Scaler  Min Max Scaler  \\\n",
       "Accuracy                   0.773712         0.775810        0.776276   \n",
       "Macro Averaged Precision   0.773394         0.775228        0.776474   \n",
       "Macro Average Recall       0.663385         0.667209        0.667546   \n",
       "F1 Macro                   0.679555         0.683990        0.684424   \n",
       "Micro Average Precision    0.773712         0.775810        0.776276   \n",
       "Micro Average Recall       0.773712         0.775810        0.776276   \n",
       "F1 Micro                   0.773712         0.775810        0.776276   \n",
       "\n",
       "Scaler                    diff_std  diff_min_max  \n",
       "Accuracy                  2.097413      2.563505  \n",
       "Macro Averaged Precision  1.834119      3.079773  \n",
       "Macro Average Recall      3.823549      4.160363  \n",
       "F1 Macro                  4.435840      4.869213  \n",
       "Micro Average Precision   2.097413      2.563505  \n",
       "Micro Average Recall      2.097413      2.563505  \n",
       "F1 Micro                  2.097413      2.563505  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test_scalers(\n",
    "    LinearSVC(max_iter=1500, random_state=100),\n",
    "    params={\"classifier__C\": np.logspace(-5, 1)},\n",
    "    name=\"LinearSVC\",\n",
    ")\n",
    "df_diff_maker(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad4ad8",
   "metadata": {},
   "source": [
    "### In not more than 50 words, present your observations on the effects of C and feature scaling on model performance. This explanation should summarize your observations from the experiments above:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7a19e",
   "metadata": {},
   "source": [
    "Different scale methods influence the parameter C, which performs the strongest regularization when data without scaling. \n",
    "\n",
    "For predicting class, the LinearSVC model achieves the largest performance improvement with scaled data compared with unscaled data. Micros is higher due to imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b946524",
   "metadata": {},
   "source": [
    "### (b) For a LogisticRegression classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e179dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Scaler, LogisticRegression\n",
      "Best parameters found are: {'classifier__C': 0.8185467307069029}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Standard Scaler, LogisticRegression\n",
      "Best parameters found are: {'classifier__C': 0.8185467307069029}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MinMax Scaler, LogisticRegression\n",
      "Best parameters found are: {'classifier__C': 0.9671798642975443}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Scaler</th>\n",
       "      <th>No Scaler</th>\n",
       "      <th>Standard Scaler</th>\n",
       "      <th>Min Max Scaler</th>\n",
       "      <th>diff_std</th>\n",
       "      <th>diff_min_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.777208</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>2.330459</td>\n",
       "      <td>2.330459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro Averaged Precision</th>\n",
       "      <td>0.772669</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.774518</td>\n",
       "      <td>0.663437</td>\n",
       "      <td>1.848531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <td>0.672206</td>\n",
       "      <td>0.677457</td>\n",
       "      <td>0.676617</td>\n",
       "      <td>5.250804</td>\n",
       "      <td>4.411572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Macro</th>\n",
       "      <td>0.689456</td>\n",
       "      <td>0.695217</td>\n",
       "      <td>0.694387</td>\n",
       "      <td>5.761248</td>\n",
       "      <td>4.931145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average Precision</th>\n",
       "      <td>0.777208</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>2.330459</td>\n",
       "      <td>2.330459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average Recall</th>\n",
       "      <td>0.777208</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>2.330459</td>\n",
       "      <td>2.330459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Micro</th>\n",
       "      <td>0.777208</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>0.779539</td>\n",
       "      <td>2.330459</td>\n",
       "      <td>2.330459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Scaler                    No Scaler  Standard Scaler  Min Max Scaler  \\\n",
       "Accuracy                   0.777208         0.779539        0.779539   \n",
       "Macro Averaged Precision   0.772669         0.773333        0.774518   \n",
       "Macro Average Recall       0.672206         0.677457        0.676617   \n",
       "F1 Macro                   0.689456         0.695217        0.694387   \n",
       "Micro Average Precision    0.777208         0.779539        0.779539   \n",
       "Micro Average Recall       0.777208         0.779539        0.779539   \n",
       "F1 Micro                   0.777208         0.779539        0.779539   \n",
       "\n",
       "Scaler                    diff_std  diff_min_max  \n",
       "Accuracy                  2.330459      2.330459  \n",
       "Macro Averaged Precision  0.663437      1.848531  \n",
       "Macro Average Recall      5.250804      4.411572  \n",
       "F1 Macro                  5.761248      4.931145  \n",
       "Micro Average Precision   2.330459      2.330459  \n",
       "Micro Average Recall      2.330459      2.330459  \n",
       "F1 Micro                  2.330459      2.330459  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test_scalers(\n",
    "    LogisticRegression(max_iter=500, random_state=100),\n",
    "    params={\"classifier__C\": np.logspace(-4, 1, num=70)},\n",
    "    name=\"LogisticRegression\",\n",
    ")\n",
    "\n",
    "df_diff_maker(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7613e6",
   "metadata": {},
   "source": [
    "### In not more than 50 words, present your observations on the effects of C and feature scaling on model performance. This explanation should summarize your observations from the experiments above:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e443d7",
   "metadata": {},
   "source": [
    "In logistic regression, the `Min_Max` scaled data has the same strength of regularization as the unscaled data.\n",
    "\n",
    "For predicting class, the logistic regression model performs best with the `Standard` scaled data accroding to highest scores in macro-average f1 value, although its macro average precision is lower than `Min_Max` scaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eebb53a",
   "metadata": {},
   "source": [
    "### (c) For a KNeighborsClassifier classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3386214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Scaler, k-nearest neighbors\n",
      "Best parameters found are: {'classifier__n_neighbors': 35, 'classifier__weights': 'uniform'}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Standard Scaler, k-nearest neighbors\n",
      "Best parameters found are: {'classifier__n_neighbors': 19, 'classifier__weights': 'uniform'}\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "MinMax Scaler, k-nearest neighbors\n",
      "Best parameters found are: {'classifier__n_neighbors': 21, 'classifier__weights': 'uniform'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Scaler</th>\n",
       "      <th>No Scaler</th>\n",
       "      <th>Standard Scaler</th>\n",
       "      <th>Min Max Scaler</th>\n",
       "      <th>diff_std</th>\n",
       "      <th>diff_min_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.759497</td>\n",
       "      <td>0.768585</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>9.088790</td>\n",
       "      <td>17.245397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro Averaged Precision</th>\n",
       "      <td>0.744538</td>\n",
       "      <td>0.752215</td>\n",
       "      <td>0.764553</td>\n",
       "      <td>7.677380</td>\n",
       "      <td>20.015172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macro Average Recall</th>\n",
       "      <td>0.647448</td>\n",
       "      <td>0.665765</td>\n",
       "      <td>0.677114</td>\n",
       "      <td>18.317113</td>\n",
       "      <td>29.666361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Macro</th>\n",
       "      <td>0.660273</td>\n",
       "      <td>0.681260</td>\n",
       "      <td>0.694235</td>\n",
       "      <td>20.987268</td>\n",
       "      <td>33.961829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average Precision</th>\n",
       "      <td>0.759497</td>\n",
       "      <td>0.768585</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>9.088790</td>\n",
       "      <td>17.245397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average Recall</th>\n",
       "      <td>0.759497</td>\n",
       "      <td>0.768585</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>9.088790</td>\n",
       "      <td>17.245397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Micro</th>\n",
       "      <td>0.759497</td>\n",
       "      <td>0.768585</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>9.088790</td>\n",
       "      <td>17.245397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Scaler                    No Scaler  Standard Scaler  Min Max Scaler  \\\n",
       "Accuracy                   0.759497         0.768585        0.776742   \n",
       "Macro Averaged Precision   0.744538         0.752215        0.764553   \n",
       "Macro Average Recall       0.647448         0.665765        0.677114   \n",
       "F1 Macro                   0.660273         0.681260        0.694235   \n",
       "Micro Average Precision    0.759497         0.768585        0.776742   \n",
       "Micro Average Recall       0.759497         0.768585        0.776742   \n",
       "F1 Micro                   0.759497         0.768585        0.776742   \n",
       "\n",
       "Scaler                     diff_std  diff_min_max  \n",
       "Accuracy                   9.088790     17.245397  \n",
       "Macro Averaged Precision   7.677380     20.015172  \n",
       "Macro Average Recall      18.317113     29.666361  \n",
       "F1 Macro                  20.987268     33.961829  \n",
       "Micro Average Precision    9.088790     17.245397  \n",
       "Micro Average Recall       9.088790     17.245397  \n",
       "F1 Micro                   9.088790     17.245397  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test_scalers(\n",
    "    KNeighborsClassifier(),\n",
    "    params={\n",
    "        \"classifier__n_neighbors\": np.linspace(1, 50, dtype=int),\n",
    "        \"classifier__weights\": [\"uniform\", \"distance\"],\n",
    "    },\n",
    "    name=\"k-nearest neighbors\",\n",
    ")\n",
    "df_diff_maker(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc9b4e",
   "metadata": {},
   "source": [
    "### In not more than 50 words, present your observations on the effect of n neighbors and feature scaling on model performance. This explanation should summarize your observations from the experiments above:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608b3ad",
   "metadata": {},
   "source": [
    "Optimal `n_nerighbours` value with unscaled data is 35, which is higher than that of scaled data.\n",
    "\n",
    "KNN scaled by `Min_Max` performs best. The macro recall is low for unscaled data, showing when considering all classes equally it performs worse, compared to micro recall which is much higher and captures imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0e68e1905cf76410184eff3c32cdb9c73fe6afd1987724612fb8659e31ade06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
